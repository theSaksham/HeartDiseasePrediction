{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    #Importing some libraries\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    #Getting rid of warnings\n",
    "    def warn(*args, **kwargs):\n",
    "        pass\n",
    "    import warnings\n",
    "    warnings.warn = warn\n",
    "    np.warnings.filterwarnings('ignore')\n",
    "\n",
    "    #START HERE\n",
    "    column_names = [\n",
    "            \"age\", #2\n",
    "            \"sex\", #3\n",
    "            \"painloc\", #4\n",
    "            \"painexer\", #5\n",
    "            \"relrest\", #6\n",
    "            \"systolic resting-blood-pressure\", #9\n",
    "            \"smoke\", #12\n",
    "            \"famhist\", #17\n",
    "            \"max-heart-rate-achieved\", #31\n",
    "            \"heart-disease\" #57\n",
    "        ]\n",
    "\n",
    "    #Importing the dataset\n",
    "    location = 'longBeachVA.csv'\n",
    "    dataset = pd.read_csv(location)\n",
    "    X = dataset.iloc[:, [2, 3, 4, 5, 6, 9, 12, 17, 31]].values\n",
    "    Y = dataset.iloc[:, 57].values\n",
    "    \n",
    "    #Replace all 'heart-disease' values greater than 0\n",
    "    for x,i in enumerate(Y):\n",
    "        if i>0:Y[x]=1\n",
    "            \n",
    "    #Plotting Data\n",
    "    #import matplotlib.pyplot as plt\n",
    "    #myB = pd.DataFrame(data=X+Y, columns=column_names)\n",
    "    #axes = scatter_matrix(myB, alpha=0.2, figsize=(6, 6), diagonal='kde')\n",
    "    #corr = myB.corr().as_matrix()\n",
    "    #for ax in axes.ravel():\n",
    "    #    ax.set_xlabel(ax.get_xlabel(), fontsize=10, rotation=90)\n",
    "    #    ax.set_ylabel(ax.get_ylabel(), fontsize=10, rotation=0)\n",
    "    #for i, j in zip(*plt.np.triu_indices_from(axes, k=1)):\n",
    "    #    axes[i, j].annotate(\"%.3f\" %corr[i,j], (0.8, 0.8), xycoords='axes fraction', ha='center', va='center')\n",
    "    #plt.show()        \n",
    "    \n",
    "    #For Missing data\n",
    "    from sklearn.preprocessing import Imputer\n",
    "    imputer = Imputer(missing_values=-9, strategy='most_frequent', axis=0)\n",
    "    imputer.fit(X[:, [6,7]])\n",
    "    X[:, [6,7]] = imputer.transform(X[:, [6,7]]) #Replace old data with new data.\n",
    "    imputer = Imputer(missing_values=-9, strategy='mean', axis=0)\n",
    "    imputer.fit(X[:, [5,8]])\n",
    "    X[:, [5,8]] = imputer.transform(X[:, [5,8]])  # Replace old data with new data.\n",
    "    \n",
    "    #Splitting the dataset into the Training set and Test set\n",
    "    from sklearn.model_selection._split import train_test_split\n",
    "    from imblearn.combine import SMOTEENN\n",
    "    smote_enn = SMOTEENN()\n",
    "    X_resampled, y_resampled = smote_enn.fit_sample(X, Y)\n",
    "    X_train, X_test, Y_Train, Y_Test = train_test_split(X_resampled, y_resampled, test_size=0.25)\n",
    "    \n",
    "    #Use actual data for tests and not the data created through imbalanced-learn\n",
    "    new = train_test_split(X, Y, test_size=0.25)\n",
    "    X_test = new[1]\n",
    "    Y_Test = new[3]\n",
    "\n",
    "    #Feature scaling\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc_X = StandardScaler()\n",
    "    X_train = sc_X.fit_transform(X_train)\n",
    "    X_test = sc_X.transform(X_test)\n",
    "\n",
    "    \n",
    "    #Using Pipeline\n",
    "    import sklearn.pipeline\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    from sklearn.decomposition import KernelPCA\n",
    "    from imblearn.pipeline import make_pipeline\n",
    "    \n",
    "    select = sklearn.feature_selection.SelectPercentile(sklearn.feature_selection.f_classif)\n",
    "    clf = MLPClassifier(solver='lbfgs', learning_rate='constant', activation='tanh')\n",
    "    kernel = KernelPCA()\n",
    "    \n",
    "    pipeline = make_pipeline(kernel, clf)\n",
    "    pipeline.fit(X_train, Y_Train)\n",
    "    \n",
    "    #Testing\n",
    "    #from sklearn import metrics\n",
    "    #from sklearn.metrics import classification_report\n",
    "    #y_pred = pipeline.predict(X_test)\n",
    "    #report = metrics.classification_report(Y_Test, y_pred)\n",
    "    #print report\n",
    "    \n",
    "    #User-input\n",
    "    v = []\n",
    "    for i in column_names[:-1]:\n",
    "        v.append(input(i+\": \"))\n",
    "    answer = np.array(v)\n",
    "    answer = answer.reshape(1,-1)\n",
    "    answer = sc_X.transform(answer)\n",
    "    \n",
    "    print(\"Predicts: \" + str(pipeline.predict(answer)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
